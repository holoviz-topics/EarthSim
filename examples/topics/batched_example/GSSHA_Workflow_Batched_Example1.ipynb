{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batched example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is the first of a series that shows how [GSSHA_Workflow.ipynb](../GSSHA_Workflow.ipynb) can be parameterized at the command line. This parameterization is designed to enable parameter sweeps, automatic report generation and other new uses for notebooks.\n",
    "\n",
    "This first notebook aims to explain the basic mechanism used to parameterize notebooks. Although this is the least user friendly of the approaches, it also requires the fewest changes to EarthSim and the associated PyViz tools.\n",
    "\n",
    "The rest of the notebook is largely the same as [GSSHA_Workflow.ipynb](../GSSHA_Workflow.ipynb) although there are a few changes that are used to expose the notebook parameters at the command line. The two parameters we choose to expose are ``rain_intensity`` and ``rain_duration``.\n",
    "\n",
    "\n",
    "1. <a href=\"#Declare_nbparams\">Declare the command line parameters</a>\n",
    "2. <a href=\"#Display_nbparams\">Display the notebook parameter widgets</a>\n",
    "3. <a href=\"#Apply_nbparams\">Apply notebook parameters and display</a>\n",
    "\n",
    "\n",
    "Once the notebook is configured to use notebook parameters, they can be set at the command line as follows:\n",
    "\n",
    "```bash\n",
    "cd examples/topics/batched_example/\n",
    "PARAM_JSON_INIT='{\"rain_intensity\":42, \"rain_duration\":50}' jupyter notebook GSSHA_Workflow_Batched_Example1.ipynb\n",
    "```\n",
    "\n",
    "You can also generate a report HTML file using ``nbconvert`` as follows:\n",
    "\n",
    "```bash\n",
    "PARAM_JSON_INIT='{\"rain_intensity\":25, \"rain_duration\":60}' jupyter nbconvert --execute GSSHA_Workflow_Batched_Example1.ipynb --output report1.html\n",
    "```\n",
    "\n",
    "This will set the ``rain_intensity`` and ``rain_duration`` values to ``42`` and ``50`` respectively from the default values of ``24`` and ``60``.\n",
    "\n",
    "The ``PARAM_JSON_INIT`` variable can be used this way to set the notebook parameters in any context where the environment variables are available in the execution context of the notebook. One major limitation of this approach is that setting environment variables on Windows requires a different syntax.\n",
    "\n",
    "In the next notebook, this approach for parameterizing notebooks is made more user friendly and generalized to work on Windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import param\n",
    "import parambokeh\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geoviews as gv\n",
    "import holoviews as hv\n",
    "import quest\n",
    "import earthsim.gssha as esgssha\n",
    "import earthsim.gssha.model as models\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "from earthsim.gssha import download_data, get_file_from_quest\n",
    "from earthsim.gssha.model import UniformRoughness, CreateGSSHAModel\n",
    "from holoviews.streams import PolyEdit, BoxEdit, PointDraw, CDSStream\n",
    "from holoviews.operation.datashader import regrid, shade\n",
    "from earthsim.io import save_shapefile, open_gssha, get_ccrs\n",
    "\n",
    "regrid.aggregator = 'max'\n",
    "\n",
    "hv.extension('bokeh')\n",
    "%output holomap='scrubber' fps=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -r ./vicksburg_south/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare the command line parameters <a id=\"Declare_nbparams\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this instance, the two chosen notebook parameters mirror those define on ``Simulation``. Mirroring parameters this way is optional and you can define any sensible notebook parameters that hook into the rest of the notebook workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotebookParams(param.Parameterized):\n",
    "    \n",
    "    rain_intensity= param.Number(default=24, bounds=(0,None), softbounds=(0,75))\n",
    "    \n",
    "    rain_duration = param.Integer(default=60,bounds=(0,None), softbounds=(0,1000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the notebook parameter widgets  <a id=\"Display_nbparams\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step makes the notebook parameters available to change at the start of the notebook, parameterizing the interactive workflow. In addition, using ``initializer=parambokeh.JSONInit()`` allows these parameters to be set from the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parambokeh.Widgets(NotebookParams, initializer=parambokeh.JSONInit())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_creator = esgssha.CreateGSSHAModel(name='Vicksburg South Model Creator',\n",
    "                                        mask_shapefile='../../data/vicksburg_watershed/watershed_boundary.shp',\n",
    "                                        grid_cell_size=90)\n",
    "parambokeh.Widgets(model_creator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the parameters of the ``roughness`` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_creator.roughness = UniformRoughness()\n",
    "parambokeh.Widgets(model_creator.roughness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw bounds to compute watershed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allows drawing a bounding box and adding points to serve as input to compute a watershed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Polygons [width=900 height=500] (fill_alpha=0 line_color='black')\n",
    "%%opts Points (size=10 color='red')\n",
    "tiles = gv.WMTS('http://c.tile.openstreetmap.org/{Z}/{X}/{Y}.png',\n",
    "                crs=ccrs.PlateCarree(), extents=(-91, 32.2, -90.8, 32.4))\n",
    "box_poly = hv.Polygons([])\n",
    "points = hv.Points([])\n",
    "box_stream = BoxEdit(source=box_poly)\n",
    "point_stream = PointDraw(source=points)\n",
    "tiles * box_poly * points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if box_stream.element:\n",
    "    element = gv.operation.project(box_stream.element, projection=ccrs.PlateCarree())\n",
    "    xs, ys = element.array().T\n",
    "    bounds = (xs[0], ys[1], xs[2], ys[0])\n",
    "    print(\"BOUNDS\", bounds)\n",
    "    \n",
    "if point_stream.element:\n",
    "    projected = gv.operation.project(point_stream.element, projection=ccrs.PlateCarree())\n",
    "    print(\"COORDINATE:\", projected.iloc[0]['x'][0], projected.iloc[0]['y'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect and edit shapefile\n",
    "\n",
    "The plot below allows editing the shapefile using a set of tools. The controls for editing are as follows:\n",
    "    \n",
    "* Double-clicking the polygon displays the vertices\n",
    "* After double-clicking the point tool is selected and vertices can be dragged around\n",
    "* By tapping on a vertex it can be selected, tapping in a new location while a single point is selected inserts a new vertex\n",
    "* Multiple points can be selected by holding shift and then tapping or using the box_select tool\n",
    "* Once multiple vertices are selected they can be deleted by selecting the point editing tool and pressing ``backspace``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Shape [width=900 height=500 tools=['box_select']] (alpha=0.5)\n",
    "mask_shape = gv.Shape.from_shapefile(model_creator.mask_shapefile).last\n",
    "tiles = gv.WMTS('http://c.tile.openstreetmap.org/{Z}/{X}/{Y}.png')\n",
    "vertex_stream = PolyEdit(source=mask_shape)\n",
    "tiles * mask_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If any edits were made to the polygon in the plot above we save the ``watershed_boundary.shp`` back out and redisplay it to confirm our edits were applied correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Shape [width=600 height=400] (alpha=0.5)\n",
    "if vertex_stream.data:\n",
    "    edited_shape_fname = '../vicksburg_watershed_edited/watershed_boundary.shp'\n",
    "    dir_name = os.path.dirname(edited_shape_fname)\n",
    "    if not os.path.isdir(dir_name): os.makedirs(dir_name)\n",
    "    save_shapefile(vertex_stream.data, edited_shape_fname, model_creator.mask_shapefile)\n",
    "    model_creator.mask_shapefile = edited_shape_fname\n",
    "    mask_shape = gv.Shape.from_shapefile(edited_shape_fname).last\n",
    "mask_shape = mask_shape.opts() # Clear options\n",
    "mask_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure simulation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = esgssha.Simulation(name='Vicksburg South Simulation', simulation_duration=60*60,\n",
    "                          rain_duration=30*60, model_creator=model_creator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply notebook parameters and display<a id=\"Apply_nbparams\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the point at which the notebook parameters hook into the workflow. In this example, the two chosen parameters ``rain_duration`` and ``rain_intensity`` are simply set on ``sim``. In more complex examples, you may decide to compute the parameters set in the workflow as a function of the availabel notebook parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.rain_duration = NotebookParams.rain_duration \n",
    "sim.rain_intensity = NotebookParams.rain_intensity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parambokeh.Widgets(sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model\n",
    "\n",
    "Note that the above code demonstrates how to collect user input, but it has not yet been connected to the remaining workflow, which uses code-based specification for the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sim.model_creator.project_name not in quest.api.get_collections():\n",
    "    quest.api.new_collection(sim.model_creator.project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parambokeh.Widgets(sim.model_creator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary workaround until workflow cleanup/parameterization is done\n",
    "if sim.model_creator.project_name == 'test_philippines_small':\n",
    "    sim.model_creator.roughness = models.GriddedRoughnessTable(\n",
    "        land_use_grid=get_file_from_quest(sim.model_creator.project_name, sim.land_use_service, 'landuse', sim.model_creator.mask_shapefile),\n",
    "        land_use_to_roughness_table='../philippines_small/land_cover_glcf_modis.txt')\n",
    "else:    \n",
    "    sim.model_creator.roughness = models.GriddedRoughnessID(\n",
    "        land_use_grid=get_file_from_quest(sim.model_creator.project_name, sim.land_use_service, 'landuse', sim.model_creator.mask_shapefile),\n",
    "        land_use_grid_id=sim.land_use_grid_id)\n",
    "\n",
    "sim.model_creator.elevation_grid_path = get_file_from_quest(sim.model_creator.project_name, sim.elevation_service, 'elevation', sim.model_creator.mask_shapefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sim.model_creator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add card for max depth\n",
    "model.project_manager.setCard('FLOOD_GRID',\n",
    "                              '{0}.fgd'.format(sim.model_creator.project_name),\n",
    "                              add_quotes=True)\n",
    "# Add time-based depth grids to simulation\n",
    "\"\"\"\n",
    "See: http://www.gsshawiki.com/Project_File:Output_Files_%E2%80%93_Required\n",
    "\n",
    "Filename or folder to output MAP_TYPE maps of overland flow depth (m) \n",
    "every MAP_FREQ minutes. If MAP_TYPE=0, then [value] is a folder name \n",
    "and output files are called \"value\\depth.####.asc\" **\n",
    "\"\"\"\n",
    "\n",
    "model.project_manager.setCard('DEPTH', '.', add_quotes=True)\n",
    "model.project_manager.setCard('MAP_FREQ', '1')\n",
    "\n",
    "# add event for simulation (optional)\n",
    "\"\"\"\n",
    "model.set_event(simulation_start=sim.simulation_start,\n",
    "                simulation_duration=timedelta(seconds=sim.simulation_duration),\n",
    "                rain_intensity=sim.rain_intensity,\n",
    "                rain_duration=timedelta(seconds=sim.rain_duration))\n",
    "\"\"\"\n",
    "# write to disk\n",
    "model.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review model inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load inputs to the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = sim.model_creator.project_name\n",
    "CRS = get_ccrs(os.path.join(name, name+'_prj.pro'))\n",
    "\n",
    "roughness_arr = open_gssha(os.path.join(name,'roughness.idx'))\n",
    "msk_arr = open_gssha(os.path.join(name, name+'.msk'))\n",
    "ele_arr = open_gssha(os.path.join(name, name+'.ele'))\n",
    "\n",
    "roughness = gv.Image(roughness_arr, crs=CRS, label='roughness.idx')\n",
    "mask = gv.Image(msk_arr, crs=CRS, label='vicksburg_south.msk')\n",
    "ele  = gv.Image(ele_arr, crs=CRS, label='vicksburg_south.ele')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shapefile vs. Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles * regrid(mask) * mask_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles * regrid(ele) * mask_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Roughness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles * regrid(roughness) * mask_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsshapy.modeling import GSSHAFramework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: how does the info here relate to that set earlier?\n",
    "\n",
    "# TODO: understand comment below\n",
    "# assuming notebook is run from examples folder\n",
    "project_path = os.path.join(sim.model_creator.project_base_directory, sim.model_creator.project_name)\n",
    "gr = GSSHAFramework(\"gssha\",\n",
    "                    project_path,\n",
    "                    \"{0}.prj\".format(sim.model_creator.project_name),\n",
    "                    gssha_simulation_start=sim.simulation_start,\n",
    "                    gssha_simulation_duration=timedelta(seconds=sim.simulation_duration),\n",
    "                    # load_simulation_datetime=True,  # use this if already set datetime params in project file\n",
    "                   )\n",
    "\n",
    "# http://www.gsshawiki.com/Model_Construction:Defining_a_uniform_precipitation_event\n",
    "gr.event_manager.add_uniform_precip_event(sim.rain_intensity, \n",
    "                                          timedelta(seconds=sim.rain_duration))\n",
    "\n",
    "gssha_event_directory = gr.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and visualize depths over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_nc = os.path.join(gssha_event_directory, 'depths.nc')\n",
    "if not os.path.isfile(depth_nc):\n",
    "    # Load depth data files\n",
    "    depth_map = hv.HoloMap(kdims=['Minute'])\n",
    "    for fname in glob.glob(os.path.join(gssha_event_directory, 'depth.*.asc')):\n",
    "        depth_arr = open_gssha(fname)\n",
    "        minute = int(fname.split('.')[-2])\n",
    "        # NOTE: Due to precision issues not all empty cells match the NaN value properly, fix later\n",
    "        depth_arr.data[depth_arr.data==depth_arr.data[0,0]] = np.NaN\n",
    "        depth_map[minute] = hv.Image(depth_arr)\n",
    "\n",
    "    # Convert data to an xarray and save as NetCDF\n",
    "    arrays = []\n",
    "    for minute, img in depth_map.items():\n",
    "        ds = hv.Dataset(img)\n",
    "        arr = ds.data.z.assign_coords(minute=minute)\n",
    "        arrays.append(arr)\n",
    "    depths = xr.concat(arrays, 'minute')\n",
    "    depths.to_netcdf(depth_nc)\n",
    "else:\n",
    "    depths = xr.open_dataset(depth_nc)\n",
    "\n",
    "depth_ds = hv.Dataset(depths)\n",
    "depth_ds.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a Dataset of depths we can convert it to a series of Images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image [width=600 height=400 logz=True xaxis=None yaxis=None] (cmap='viridis') Histogram {+framewise}\n",
    "regrid(depth_ds.to(hv.Image, ['x', 'y'])).redim.range(z=(0, 0.04)).hist(bin_range=(0, 0.04))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also lay out the plots over time to allow for easier comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image [width=300 height=300 logz=True xaxis=None yaxis=None] (cmap='viridis')\n",
    "regrid(depth_ds.select(minute=range(10, 70, 10)).to(hv.Image, ['x', 'y']).redim.range(z=(0, 0.04))).layout().cols(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flood Grid Depth\n",
    "\n",
    "(Maximum flood depth over the course of the simulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image [width=600 height=400] (cmap='viridis')\n",
    "fgd_arr = open_gssha(os.path.join(gssha_event_directory,'{0}.fgd'.format(sim.model_creator.project_name)))\n",
    "fgd = gv.Image(fgd_arr, crs=CRS, label='vicksburg_south.fgd').redim.range(z=(0, 0.04))\n",
    "regrid(fgd, streams=[hv.streams.RangeXY]).redim.range(z=(0, 0.04))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the simulation speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Spikes [width=600]\n",
    "times = np.array([os.path.getmtime(f) for f in glob.glob(os.path.join(gssha_event_directory, 'depth*.asc'))] )\n",
    "minutes = (times-times[0])/60\n",
    "hv.Spikes(minutes, kdims=['Real Time (minutes)'], label='Time elapsed for each minute of simulation time') +\\\n",
    "hv.Curve(np.diff(minutes), kdims=['Simulation Time (min)'], vdims=[('runtime', 'Runtime per minute simulation time')]).redim.range(runtime=(0, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here if the \"spikes\" are regularly spaced, simulation time is regularly scaled with real time, and so you should be able read out the approximate time to expect per unit of simulation time."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
