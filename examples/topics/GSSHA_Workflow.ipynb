{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows a sample workflow for running hydrology simulations using the GSSHA rectangularly gridded simulator, supported by a suite of primarily open-source Python libraries.  The workflow consists of:\n",
    "\n",
    "1. Selecting parameters using widgets in a Jupyter notebook to control the model to simulate, including a watershed shape file.\n",
    "2. Visualizing the watershed shape in a geographic context (projected into a suitable coordinate system and overlaid on map tiles from a web tile server).\n",
    "3. If necessary, editing that watershed shape by hand and creating a new shape file with the edited result.\n",
    "4. Selecting parameters to control the simulation, potentially overriding some selected earlier for the model creation (e.g. if running numerous conditions as a parameter sweep).\n",
    "5. Visualizing and reviewing the inputs to the simulation.\n",
    "6. Running the underlying simulation, collecting data on flood depth at each time point as well as the overall maximum flood depth per grid cell.\n",
    "7. Visualizing the flood depth over time and the maximum flood depth.\n",
    "8. Analyzing the simulation speed to help shape expectations for computational requirements for future runs.\n",
    "\n",
    "Each of these steps is configured directly in this notebook, and can thus easily be scripted or iterated as needed. The set of parameters and precisely how they are configured is still being improved, and it can likely be made into a better match to users' needs in this domain. This workflow relies on fast raster regridding added to [Datashader](http://datashader.org/user_guide/5_Rasters.html) and exposed via [HoloViews](http://holoviews.org) as part of the EarthSim project.\n",
    "\n",
    "The underlying environment needed to run this workflow is set up as described in the [README](https://github.com/ContinuumIO/EarthSim/blob/master/README.md), and though already functional will need to be greatly simplified to be more usable and maintainable in practice. The workflow currently relies on downloading data from external servers that can be slow to access from some parts of the internet, so you may see widely varying runtime speeds, especially the first time it is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",    
    "\n",
    "import param\n",
    "import paramnb\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geoviews as gv\n",
    "import holoviews as hv\n",
    "import quest\n",
    "import earthsim.gssha as esgssha\n",
    "import earthsim.gssha.model as models\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "from earthsim.gssha import download_data, get_file_from_quest\n",
    "from holoviews.streams import PolyEdit, BoxEdit, PointDraw, CDSStream\n",
    "from holoviews.operation.datashader import regrid, shade\n",
    "from earthsim.io import save_shapefile, open_gssha, get_ccrs\n",
    "\n",
    "regrid.aggregator = 'max'\n",
    "\n",
    "hv.extension('bokeh')\n",
    "%output holomap='scrubber' fps=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('./vicksburg_south')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_creator = esgssha.CreateGSSHAModel(name='Vicksburg South Model Creator',\n",
    "                                        mask_shapefile='../data/vicksburg_watershed/watershed_boundary.shp',\n",
    "                                        grid_cell_size=90)\n",
    "paramnb.Widgets(model_creator,initializer=paramnb.JSONInit())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw bounds to compute watershed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allows drawing a bounding box and adding points to serve as input to compute a watershed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Polygons [width=900 height=500] (fill_alpha=0 line_color='black')\n",
    "%%opts Points (size=10 color='red')\n",
    "tiles = gv.WMTS('http://c.tile.openstreetmap.org/{Z}/{X}/{Y}.png',\n",
    "                crs=ccrs.PlateCarree(), extents=(-91, 32.2, -90.8, 32.4))\n",
    "box_poly = hv.Polygons([])\n",
    "points = hv.Points([])\n",
    "box_stream = BoxEdit(source=box_poly)\n",
    "point_stream = PointDraw(source=points)\n",
    "tiles * box_poly * points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if box_stream.element:\n",
    "    element = gv.operation.project(box_stream.element, projection=ccrs.PlateCarree())\n",
    "    xs, ys = element.array().T\n",
    "    bounds = (xs[0], ys[1], xs[2], ys[0])\n",
    "    print(\"BOUNDS\", bounds)\n",
    "    \n",
    "if point_stream.element:\n",
    "    projected = gv.operation.project(point_stream.element, projection=ccrs.PlateCarree())\n",
    "    print(\"COORDINATE:\", projected.iloc[0]['x'][0], projected.iloc[0]['y'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect and edit shapefile\n",
    "\n",
    "The plot below allows editing the shapefile using a set of tools. The controls for editing are as follows:\n",
    "    \n",
    "* Double-clicking the polygon displays the vertices\n",
    "* After double-clicking the point tool is selected and vertices can be dragged around\n",
    "* By tapping on a vertex it can be selected, tapping in a new location while a single point is selected inserts a new vertex\n",
    "* Multiple points can be selected by holding shift and then tapping or using the box_select tool\n",
    "* Once multiple vertices are selected they can be deleted by selecting the point editing tool and pressing ``backspace``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Shape [width=900 height=500 tools=['box_select']] (alpha=0.5)\n",
    "mask_shape = gv.Shape.from_shapefile(model_creator.mask_shapefile).last\n",
    "tiles = gv.WMTS('http://c.tile.openstreetmap.org/{Z}/{X}/{Y}.png')\n",
    "vertex_stream = PolyEdit(source=mask_shape)\n",
    "tiles * mask_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If any edits were made to the polygon in the plot above we save the ``watershed_boundary.shp`` back out and redisplay it to confirm our edits were applied correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Shape [width=600 height=400] (alpha=0.5)\n",
    "if vertex_stream.data:\n",
    "    edited_shape_fname = './vicksburg_watershed_edited/watershed_boundary.shp'\n",
    "    dir_name = os.path.dirname(edited_shape_fname)\n",
    "    if not os.path.isdir(dir_name): os.makedirs(dir_name)\n",
    "    save_shapefile(vertex_stream.data, edited_shape_fname, model_creator.mask_shapefile)\n",
    "    model_creator.mask_shapefile = edited_shape_fname\n",
    "    mask_shape = gv.Shape.from_shapefile(edited_shape_fname).last\n",
    "mask_shape = mask_shape.opts() # Clear options\n",
    "mask_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure simulation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = esgssha.Simulation(name='Vicksburg South Simulation', simulation_duration=60*60,\n",
    "                          rain_duration=30*60, model_creator=model_creator)\n",
    "paramnb.Widgets(sim,initializer=paramnb.JSONInit())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model\n",
    "\n",
    "Note that the above code demonstrates how to collect user input, but it has not yet been connected to the remaining workflow, which uses code-based specification for the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sim.model_creator.project_name not in quest.api.get_collections():\n",
    "    quest.api.new_collection(sim.model_creator.project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramnb.Widgets(sim.model_creator,initializer=paramnb.JSONInit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary workaround until workflow cleanup/parameterization is done\n",
    "if sim.model_creator.project_name == 'test_philippines_small':\n",
    "    sim.model_creator.roughness = models.GriddedRoughnessTable(\n",
    "        land_use_grid=get_file_from_quest(sim.model_creator.project_name, sim.land_use_service, 'landuse', sim.model_creator.mask_shapefile),\n",
    "        land_use_to_roughness_table='./philippines_small/land_cover_glcf_modis.txt')\n",
    "else:    \n",
    "    sim.model_creator.roughness = models.GriddedRoughnessID(\n",
    "        land_use_grid=get_file_from_quest(sim.model_creator.project_name, sim.land_use_service, 'landuse', sim.model_creator.mask_shapefile),\n",
    "        land_use_grid_id=sim.land_use_grid_id)\n",
    "\n",
    "sim.model_creator.elevation_grid_path = get_file_from_quest(sim.model_creator.project_name, sim.elevation_service, 'elevation', sim.model_creator.mask_shapefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sim.model_creator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add card for max depth\n",
    "model.project_manager.setCard('FLOOD_GRID',\n",
    "                              '{0}.fgd'.format(sim.model_creator.project_name),\n",
    "                              add_quotes=True)\n",
    "# Add time-based depth grids to simulation\n",
    "\"\"\"\n",
    "See: http://www.gsshawiki.com/Project_File:Output_Files_%E2%80%93_Required\n",
    "\n",
    "Filename or folder to output MAP_TYPE maps of overland flow depth (m) \n",
    "every MAP_FREQ minutes. If MAP_TYPE=0, then [value] is a folder name \n",
    "and output files are called \"value\\depth.####.asc\" **\n",
    "\"\"\"\n",
    "\n",
    "model.project_manager.setCard('DEPTH', '.', add_quotes=True)\n",
    "model.project_manager.setCard('MAP_FREQ', '1')\n",
    "\n",
    "# add event for simulation (optional)\n",
    "\"\"\"\n",
    "model.set_event(simulation_start=sim.simulation_start,\n",
    "                simulation_duration=timedelta(seconds=sim.simulation_duration),\n",
    "                rain_intensity=sim.rain_intensity,\n",
    "                rain_duration=timedelta(seconds=sim.rain_duration))\n",
    "\"\"\"\n",
    "# write to disk\n",
    "model.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review model inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load inputs to the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = sim.model_creator.project_name\n",
    "CRS = get_ccrs(os.path.join(name, name+'_prj.pro'))\n",
    "\n",
    "roughness_arr = open_gssha(os.path.join(name,'roughness.idx'))\n",
    "msk_arr = open_gssha(os.path.join(name, name+'.msk'))\n",
    "ele_arr = open_gssha(os.path.join(name, name+'.ele'))\n",
    "\n",
    "roughness = gv.Image(roughness_arr, crs=CRS, label='roughness.idx')\n",
    "mask = gv.Image(msk_arr, crs=CRS, label='vicksburg_south.msk')\n",
    "ele  = gv.Image(ele_arr, crs=CRS, label='vicksburg_south.ele')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shapefile vs. Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles * regrid(mask) * mask_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles * regrid(ele) * mask_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Roughness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles * regrid(roughness) * mask_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsshapy.modeling import GSSHAFramework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: how does the info here relate to that set earlier?\n",
    "\n",
    "# TODO: understand comment below\n",
    "# assuming notebook is run from examples folder\n",
    "project_path = os.path.join(sim.model_creator.project_base_directory, sim.model_creator.project_name)\n",
    "gr = GSSHAFramework(\"gssha\",\n",
    "                    project_path,\n",
    "                    \"{0}.prj\".format(sim.model_creator.project_name),\n",
    "                    gssha_simulation_start=sim.simulation_start,\n",
    "                    gssha_simulation_duration=timedelta(seconds=sim.simulation_duration),\n",
    "                    # load_simulation_datetime=True,  # use this if already set datetime params in project file\n",
    "                   )\n",
    "\n",
    "# http://www.gsshawiki.com/Model_Construction:Defining_a_uniform_precipitation_event\n",
    "gr.event_manager.add_uniform_precip_event(sim.rain_intensity, \n",
    "                                          timedelta(seconds=sim.rain_duration))\n",
    "\n",
    "gssha_event_directory = gr.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and visualize depths over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_nc = os.path.join(gssha_event_directory, 'depths.nc')\n",
    "if not os.path.isfile(depth_nc):\n",
    "    # Load depth data files\n",
    "    depth_map = hv.HoloMap(kdims=['Minute'])\n",
    "    for fname in glob.glob(os.path.join(gssha_event_directory, 'depth.*.asc')):\n",
    "        depth_arr = open_gssha(fname)\n",
    "        minute = int(fname.split('.')[-2])\n",
    "        # NOTE: Due to precision issues not all empty cells match the NaN value properly, fix later\n",
    "        depth_arr.data[depth_arr.data==depth_arr.data[0,0]] = np.NaN\n",
    "        depth_map[minute] = hv.Image(depth_arr)\n",
    "\n",
    "    # Convert data to an xarray and save as NetCDF\n",
    "    arrays = []\n",
    "    for minute, img in depth_map.items():\n",
    "        ds = hv.Dataset(img)\n",
    "        arr = ds.data.z.assign_coords(minute=minute)\n",
    "        arrays.append(arr)\n",
    "    depths = xr.concat(arrays, 'minute')\n",
    "    depths.to_netcdf(depth_nc)\n",
    "else:\n",
    "    depths = xr.open_dataset(depth_nc)\n",
    "\n",
    "depth_ds = hv.Dataset(depths)\n",
    "depth_ds.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a Dataset of depths we can convert it to a series of Images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image [width=600 height=400 logz=True xaxis=None yaxis=None] (cmap='viridis') Histogram {+framewise}\n",
    "regrid(depth_ds.to(hv.Image, ['x', 'y'])).redim.range(z=(0, 0.04)).hist(bin_range=(0, 0.04))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also lay out the plots over time to allow for easier comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image [width=300 height=300 logz=True xaxis=None yaxis=None] (cmap='viridis')\n",
    "regrid(depth_ds.select(minute=range(10, 70, 10)).to(hv.Image, ['x', 'y']).redim.range(z=(0, 0.04))).layout().cols(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flood Grid Depth\n",
    "\n",
    "(Maximum flood depth over the course of the simulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image [width=600 height=400] (cmap='viridis')\n",
    "fgd_arr = open_gssha(os.path.join(gssha_event_directory,'{0}.fgd'.format(sim.model_creator.project_name)))\n",
    "fgd = gv.Image(fgd_arr, crs=CRS, label='vicksburg_south.fgd').redim.range(z=(0, 0.04))\n",
    "regrid(fgd, streams=[hv.streams.RangeXY]).redim.range(z=(0, 0.04))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the simulation speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Spikes [width=600]\n",
    "times = np.array([os.path.getmtime(f) for f in glob.glob(os.path.join(gssha_event_directory, 'depth*.asc'))] )\n",
    "minutes = (times-times[0])/60\n",
    "hv.Spikes(minutes, kdims=['Real Time (minutes)'], label='Time elapsed for each minute of simulation time') +\\\n",
    "hv.Curve(np.diff(minutes), kdims=['Simulation Time (min)'], vdims=[('runtime', 'Runtime per minute simulation time')]).redim.range(runtime=(0, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here if the \"spikes\" are regularly spaced, simulation time is regularly scaled with real time, and so you should be able read out the approximate time to expect per unit of simulation time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
